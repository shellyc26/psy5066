<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>One-sample hypothesis tests</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs-2.10/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/rladies.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/rladies-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="my-theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# One-sample hypothesis tests

---





## Today...

* One-sample *t*-tests

- _Note: Slides 10 &amp; 11 changed on 11/11/2020. N was updated to 197, not 227_

---

# What are the steps of NHST?

--

1. Define null and alternative hypothesis.

--

2. Set and justify alpha level.

--

3. Determine which sampling distribution ( `\(z\)`, `\(t\)`, or `\(\chi^2\)` for now)

--

4. Calculate parameters of your sampling distribution under the null.
  * If `\(z\)`, calculate `\(\mu\)` and `\(\sigma_M\)`

--

5. Calculate test statistic under the null.
  * If `\(z\)`, `\(\frac{\bar{X} - \mu}{\sigma_M}\)`
  
--

6. Calculate probability of that test statistic or more extreme under the null, and compare to alpha.

---

One-sample tests compare your given sample with a "known" population.

* Research question: does this sample come from this population?

**Hypotheses**

`\(H_0\)`: Yes, this sample comes from this population.

`\(H_1\)`: No, this sample comes from a different population. 



---
## Example

The [sample data](../data/cenus_at_school_missouri.csv) were obtained from Census at School, a website developed by the American Statistical Association to help students in the 4th through 12th grades understand statistical problem-solving. 

  * The site sponsors a survey that students can complete and a database that students and instructors can use to illustrate principles in quantitative methods.  
  * The database includes students from all 50 states, from grade levels 4 through 12, both boys and girls,  who have completed the survey dating back to 2010.  
  


---

## Comparing Means

Comparing means is usually done with the *t*-test, of which there are several forms.

The one-sample *t*-test is appropriate when a single sample mean is compared to a population mean but the population standard deviation is unknown.  A sample estimate of the population standard deviation is used instead.  The appropriate sampling distribution is the t-distribution, with N-1 degrees of freedom.

`$$t_{df=N-1} = \frac{\bar{X}-\mu}{\frac{\hat{\sigma}}{\sqrt{N}}}$$`
The heavier tails of the t-distribution, especially for small N, are the penalty we pay for having to estimate the population standard deviation from the sample.

---

## One-sample *t*-tests

*t*-tests were developed by William Sealy Gosset, who was a chemist studying the grains used in making beer. (He worked for Guinness.)

* Specifically, he wanted to know whether particular strains of grain made better or worse beer than the standard. 

* He developed the *t*-test, to test small samples of beer against a population with an unknown standard deviation.
  
  * Probably had input from Karl Pearson and Ronald Fisher
  
* Published this as "Student" because Guinness wouldn't let him share company secrets. 

---

## One-sample *t*-tests

| | Z-test | *t*-test |
| --|--------|--------|
| `\(\large{\mu}\)` | known | known |
| `\(\sigma\)` | known |unknown |
| sem or `\(\sigma_M\)` | `\(\frac{\sigma}{\sqrt{N}}\)` | `\(\frac{\hat{\sigma}}{\sqrt{N}}\)` |
|Probability distribution | standard normal | t |
| DF | none | N-1 |
| Tails | One or two | One or two |
| Critical value ( `\(\alpha = .05, two-tailed\)` | 1.96 | Depends on DF |

---

## Always Assuming...

**Normality.** We assume the sampling distribution of the mean is normally distributed.

**Independence.** Observations in the dataset are not associated with one another. Put another way, collecting a score from Participant A doesn't tell me anything about what Participant B will say.

---

## A brief example

Using the same Census at School data, we find that Oregon students who participated in a memory game ( `\(N = 51\)` ) completed the game in an average time of `\(45.93\)` seconds ( `\(s = 13.05\)` ). We know that the average US student completed the game in `\(45.04\)` seconds. How do our students compare?

.tiny[We're using data from Missouri in 2021 only]


```r
library(tidyverse)
school %&gt;% 
  summarize(meanMemory = mean(Score_in_memory_game),
            sdMemory = sd(Score_in_memory_game))
```

```
##   meanMemory sdMemory
## 1   45.93098 13.05054
```

```r
nrow(school)
```

```
## [1] 51
```


---

## A brief example

Using the same Census at School data, we find that Oregon students who participated in a memory game ( `\(N = 51\)` ) completed the game in an average time of `\(45.93\)` seconds ( `\(s = 13.05\)` ). We know that the average US student completed the game in `\(45.05\)` seconds. How do our students compare?

.tiny[We're using data from Missouri in 2021 only]


**Hypotheses**

`\(H_0: \mu = 45.05\)`

`\(H_1: \mu \neq 45.05\)`

---

`$$\mu = 45.05$$`

`$$N = 51$$`

$$ \bar{X} = 45.93 $$

$$ s = 13.05 $$






```r
t.test(x = school$Score_in_memory_game, mu = 45.05, 
       alternative = "two.sided")
```

```
## 
## 	One Sample t-test
## 
## data:  school$Score_in_memory_game
## t = 0.48208, df = 50, p-value = 0.6318
## alternative hypothesis: true mean is not equal to 45.05
## 95 percent confidence interval:
##  42.26046 49.60150
## sample estimates:
## mean of x 
##  45.93098
```


---


```r
lsr::oneSampleTTest(x = school$Score_in_memory_game, 
                    mu = 45.05, one.sided = FALSE)
```

```
## 
##    One sample t-test 
## 
## Data variable:   school$Score_in_memory_game 
## 
## Descriptive statistics: 
##             Score_in_memory_game
##    mean                   45.931
##    std dev.               13.051
## 
## Hypotheses: 
##    null:        population mean equals 45.05 
##    alternative: population mean not equal to 45.05 
## 
## Test results: 
##    t-statistic:  0.482 
##    degrees of freedom:  50 
##    p-value:  0.632 
## 
## Other information: 
##    two-sided 95% confidence interval:  [42.26, 49.602] 
##    estimated effect size (Cohen's d):  0.068
```

---

## Cohen's D

Cohen suggested one of the most common effect size estimates—the standardized mean difference—useful when comparing a group mean to a population mean or two group means to each other. 

`$$\delta = \frac{\mu_1 - \mu_0}{\sigma} \approx d = \frac{\bar{X}-\mu}{\hat{\sigma}}$$`

--

Cohen’s d is in the standard deviation (Z) metric. Why does this matter?


---
## Cohen's D

Cohens’s d for these data is .068.  In other words, the sample mean differs from the population mean by .068 standard deviation units. 

Cohen (1988) suggests the following guidelines for interpreting the size of d:


- .2 = Small

- .5 = Medium

- .8 = Large	

.tiny[Cohen, J. (1988), Statistical power analysis for the behavioral sciences (2nd Ed.). Hillsdale: Lawrence Erlbaum.]

--

Not bounded by 1 the way a correlation is bounded
---

Another useful metric is the overlap between the two distributions -- the smaller the overlap, the farther apart the distributions

![](14-one_sample_files/figure-html/unnamed-chunk-6-1.png)&lt;!-- --&gt;

---

## You Try!

Download the data: [sample data](../data/cenus_at_school_missouri.csv)


```r
library(tidyverse)
school_pollution = read.csv(here("data/cenus_at_school_missouri.csv"))
school_pollution = school %&gt;%
  filter(!is.na(Importance_reducing_pollution))
```

.small[ You'll need to change the working directory to wherever you downloaded the file]

---

## You Try!

Students were asked the following: *"How important is reducing pollution to you?"*. They were give options of 0 (not important) to 1000 (very important). 

The average rating across the nation is `\(762.52\)`. 

---
## You Try!

Using the same data:

**Group 1**: Calculate the `\(t\)` statistic "by hand".

--

**Group 2**: Calculate the `\(p\)`-value and 95% CI. Interpret! Use `R` to get the `\(p\)`-value, but calculate 95% CI "by hand".

--

**Group 3**: Calculate Cohen's D "by hand". Interpret!

---
### Let's do it together

**Step 1**: Get the test statistic


```r
school_pollution %&gt;% 
  summarize(meanPollution = round(mean(Importance_reducing_pollution),
                                  digits = 3),
            sdPollution = round(sd(Importance_reducing_pollution),
                                digits = 3))
```

```
##   meanPollution sdPollution
## 1       718.673     297.403
```

```r
nrow(school_pollution)
```

```
## [1] 49
```

--

$$ \frac{718.673 - 762.52}{\frac{297.403}{\sqrt{49}}} $$

--


```r
(718.673 - 762.52) / (297.403/sqrt(49))
```

```
## [1] -1.032031
```

---

## Let's do it together

**Step 2a**: Get the `\(p\)`-value. Interpret


```r
t = (718.673 - 762.52) / (297.403/sqrt(49))
N = nrow(school_pollution)
2 * pt(q = t, df = N-1, lower.tail = TRUE)
```

```
## [1] 0.3072299
```

--

The probability of obtaining a test statistic of -1.032 or more extreme, given the null hypothesis is true is .307. This is above our standard threshold of .05. We therefore cannot reject the null hypothesis. We retain the null hypothesis that states that our sample mean and population mean are the same. 

---
**Step 2b**: Get the 95% CIs. Interpret

`\(\bar{X} \pm [t_{.975, df}\frac{\hat{\sigma}}{\sqrt{N}}]\)`


```r
# we have N stored from previous slide
xbar = 718.673
sem = 297.403/sqrt(49)

ci_lb_t = xbar - sem * qt(p = .975, df = N-1)
ci_ub_t = xbar + sem * qt(p = .975, df = N-1)

ci_lb_t
```

```
## [1] 633.2489
```

```r
ci_ub_t
```

```
## [1] 804.0971
```

--

If we carried out random sampling from the population a large number of times, and each time we calculated the 95% confidence interval, we would expect 95% of those intervals to contain the true population mean, which is likely somewhere between 633.249 and 804.097

--

$$ t(48) = -1.032 \\
CI_{95}[633.249, 804.097] $$

---
**Step 3**: Get Cohen's *d*. Interpret

`$$d = \frac{\bar{X}-\mu}{\hat{\sigma}}$$`

```r
# we have xbar from before
stdev = 297.403
mu = 762.52

d = abs((xbar - mu) / stdev)
d
```

```
## [1] 0.1474329
```

--

`$$t(48) = -1.032 \\ 
CI_{95}[633.249, 804.097] \\
\text{Cohen's d} = 0.147$$`

--

The standardized difference in means is quite small, with a Cohen's *d* equal to 0.147. According to Cohen (1988), this is considered a small effect size. 

---



```r
lsr::oneSampleTTest(x = school_pollution$Importance_reducing_pollution, 
                    mu = 762.52, one.sided = FALSE)
```

```
## 
##    One sample t-test 
## 
## Data variable:   school_pollution$Importance_reducing_pollution 
## 
## Descriptive statistics: 
##             Importance_reducing_pollution
##    mean                           718.673
##    std dev.                       297.403
## 
## Hypotheses: 
##    null:        population mean equals 762.52 
##    alternative: population mean not equal to 762.52 
## 
## Test results: 
##    t-statistic:  -1.032 
##    degrees of freedom:  48 
##    p-value:  0.307 
## 
## Other information: 
##    two-sided 95% confidence interval:  [633.249, 804.097] 
##    estimated effect size (Cohen's d):  0.147
```

---

### The usefulness of the one-sample *t*-test

How often will you conducted a one-sample *t*-test on raw data?

--

* (Probably) never

--

How often will you come across one-sample *t*-tests?

--

* A lot!

The one-sample *t*-test is used to test coefficients in a model. 

---


```r
model = lm(Petal.Width ~ Species, data = iris)
summary(model)
```

```
## 
## Call:
## lm(formula = Petal.Width ~ Species, data = iris)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -0.626 -0.126 -0.026  0.154  0.474 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)        0.24600    0.02894    8.50 1.96e-14 ***
## Speciesversicolor  1.08000    0.04093   26.39  &lt; 2e-16 ***
## Speciesvirginica   1.78000    0.04093   43.49  &lt; 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.2047 on 147 degrees of freedom
## Multiple R-squared:  0.9289,	Adjusted R-squared:  0.9279 
## F-statistic:   960 on 2 and 147 DF,  p-value: &lt; 2.2e-16
```

---

## If time...

Accessing your results in `R`

- Go through list objects
- Go through `broom`

---

class: inverse
# Next time...

Comparing two means

![](images/jolo.png)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
