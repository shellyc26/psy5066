<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Comparisons and Contrasts</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs-2.25/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="my-theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Comparisons and Contrasts
]

---





## Recap

  - `\(E_R - E_F = SS_\text{Between}\)`
  - `\(SS_\text{Between}\)` is the differences in means
  - `\(SS_\text{Within}\)` is a hodgepodge of individual differences and random error
  
--

  - `\(\eta^2\)` Rules of thumb
      - .01 - .059 = small
      - .06 - .139 = medium
      - \&gt; .14 = large
  - PRE Rules of thumb:
      - 0 - .1 = small/weak
      - .1 - .4 = medium/moderate
      - \&gt;.4 = large/strong

---

## When comparing more than 2 groups...

**Omnibus** test:

$$ H_0: \mu_1 = \mu_2 = \mu_3 = \mu_4 $$
--

The alternative hypothesis:


`$$H_A: \mu_1 \neq \mu_2 \neq \mu_3 \neq \mu_4 \\
H_A: \mu_1 \neq \mu_2 = \mu_3 = \mu_4$$`

---

## *t*-tests vs. Oneway ANOVA

You *could* run separate *t*-tests compring any two of the four groups:

.pull-left[
- `\(\mu_1 \neq \mu_2\)`
- `\(\mu_1 \neq \mu_3\)`
- `\(\mu_1 \neq \mu_4\)`
- `\(\mu_2 \neq \mu_3\)`
- `\(\mu_2 \neq \mu_4\)`
- `\(\mu_3 \neq \mu_4\)`
]

.pull-right[
Number of tests (*m*) is: 

`$$m = \frac{a(a-1)}{2}$$`
]

---

## Family-wise Error Rate (FWER)

The probability that one or more of your "family" of multiple tests is false
      
- P(making an error) = `\(\alpha\)`
- P(not making an error) = `\(1 - \alpha\)`
- P(not making an error in m tests) = `\((1-\alpha)^m\)`
- P(making at least 1 error in m tests) = `\(1 - (1-\alpha)^m\)`

--

FWER for 6 tests with an `\(\alpha = .05\)`:

`$$1-(1-.05)^6 \\
1-(.95)^6 \\
1-.735 \\
.265$$`
      
---

## Why use ANOVA and not a bunch of *t*-tests?

- Inflates Type I error rate!

- Going from the probability of a Type I error being .05 to .265!!! Yikes!!!

- Using ANOVA helps control for inflated FWER by using a single, cohesive statistical tests rather than a series of *t*-tests! It allows a test of the various means while maintaining an *a priori* alpha level. 

---

## You can't choose your family. Kinda.

What is the family? Is it:

- all 6 tests?
- just `\(\mu_1\)` vs. the other tests with `\(\mu_1\)` in it? 
- `\(\mu_1\)` vs. the AVERAGE of `\(\mu_2\)`, `\(\mu_3\)`, `\(\mu_4\)`?

--

Some say that the "family" of tests could mean...
- All tests related to a specific research question, within a single study
- All tests using the same data
- All tests related to a specific research question, across all studies
- All tests reported in a paper
- Any of the above plus the tests that were run for that topic but not reported

ðŸ¤¦

---
class: center

## Who is the best Batman

![Batmen](images/batman.png)

---

## Who is the best Batman

![](images/bat1.png)

---

## Who is the best Batman

![](images/bat2.png)

---

## Who is the best Batman

![](images/bat3.png)

---

## Who is the best Batman

![](images/bat4.png)
---

## Who is the best Batman

`$$F = \frac{(E_R - E_F) / (df_R - df_F)}{E_F/df_F} \\
F = \frac{(25-12.8)/(19-16)}{12.8/16} \\
F = 5.083$$`

Critical value for `\(\alpha = .05\)`,  `\(F(3, 16) = 2.462\)`

--

#### What does this tell us? 

--

It doesn't answer the question the internet was made for!

---

## A Priori vs. Post Hoc

If *a priori* (aka planned ahead):
- You could use a whole bunch of `\(t\)`-tests. But that doesn't limit the number of tests that you are running! So you could get an inflated FWER and increase your chances of making a Type I error.
  - Rather than running a lot of `\(t\)`-tests, you could use a planned contrast (wait for it).
- Another option is to reduce your `\(\alpha\)` for each comparison that you make as a "penalty"
  -  `\(t\)`-test + Bonferonni correction
- Contrasts (and maybe some Bonferonni correction, but mostly contrasts alone) is the ideal

---
## A Priori vs. Post Hoc

What if you really don't know the outcome? Post-hoc tests!
- Tukey
- Scheffe

---

class: inverse, center, middle

# Multiple Comparisons Corrections

---

## Pairwise Tests vs. Other Contrasts

.pull-left[

**Pairwise**:

- Is Christian Bale ranked higher than Adam West?
- Is Ben Affleck ranked lowest of all the Batmen?
]

.pull-right[

**Contrast**:

- Do Batmen from over 20 years ago rank lower than recent Batmen?
- Do people rank Michael Keaton as better than the average Batman?
]

---

## Bonferonni Correction

Take the number of planned tests that you have, and divide your alpha level equally amongst the tests.

`\(\alpha = .05\)` and we have 6 planned tests, `\(.05/6 = .0083\)`. `\(.0083\)` is our new alpha!

---

## With Bonferonni Correction

2 of our tests would be considered "significant", *p* less than .0083

![](images/bat5.png)
---

## Without Bonferonni Correction

3 of our tests would be considered "significant", *p* less than .05

![](images/bat6.png)

---

## Bonferonni Correction

What issues might present with the Bonferonni correction for multiple comparisons?

&lt;center&gt;

![](images/bonferonniCartoon.png)

---
## Bonferonni Correction

[Perneger (1998)](https://doi.org/10.1136/bmj.316.7139.1236)

![](images/bonferonniIssues.png)

---

## If you only care about pairwise...

- Tukey's HSD (Honestly significant difference)

- What is the minimal difference between two means needed to declare something significantly different?

---

## Tukey's HSD

- What is the minimal difference between two means needed to declare something significantly different?

- Usually, we're looking for the `\(q\)` statistic, but we can rearrange the equation!

`$$q = \frac{\text{Mean 1 - Mean 2}}{\sqrt{\frac{\text{MS Within}}{\text{N per group}}}} \\
\text{Mean 1 - Mean 2} = q\sqrt{\frac{\text{MS Within}}{\text{N per group}}}$$`

---

## Tukey's HSD

`\(\text{Mean 1 - Mean 2} = q\sqrt{\frac{\text{MS Within}}{\text{N per group}}}\)`

- MS within = .8, N per group = .5, q = 4.05 (you get this from a table based on your df and number of groups; or I give it to you)

- Mean 1 - Mean 2 = 1.62

&gt; The minimial difference between 2 means to declare something significantly different needs to be 1.62

---

## Back to the data

Means:

- Adam West = 3
- Michael Keaton = 2.6
- Christian Bale = 1.2
- Ben Affleck = 3.2

--

Comparing Adam West to Christian Bale, 3 - 1.2 = 1.8 (sig)
Comparing Christian Bale to Ben Affleck, 3.2 - 1.2 = 2 (sig)
Comparing Adam West to Michael Keaton, 3 - 2.6 = .4 (not sig)

... the rest are not significant

---

## When all else fails

- **Scheffe** test

- Benefits: can be used for pairwise and/or other contrasts; often used with unequal sample sizes

- Downsides: ridiculously conservative

- Howell (2007): *"I can't imagine when I would ever use it, but I include it here because it is such a standard test"*

---
class: inverse, center, middle

# Contrasts

---

## General formula for a contrast

`$$F = \frac{\psi^2}{MS_\text{Within}\Sigma(c_j^2/n_j)}$$`

`\(\psi\)` (Psi) is our contrast

`\(c\)` reflects the **coefficients** for that contrast

---

## Is there a recency effect in our data?

- Are current Batmen rated as better than past Batmen?

- `\(H_0\)`: Average (Adam West and Michael Keaton) = Average (Christian Bale and Ben Affleck)
- `\(H_A\)`: Average (Adam West and Michael Keaton) `\(\neq\)` Average (Christian Bale and Ben Affleck)

---

## Defining the contrasts

**Coefficients must equal 0**

- -.5(Adam West and Michael Keaton) vs. .5(Christian Bale and Ben Affleck)

- The `\(c\)`'s in this contrast are -.5, -.5, .5, .5

---

## Calculate `\(\psi\)`

Means:

- Adam West = 3
- Michael Keaton = 2.6
- Christian Bale = 1.2
- Ben Affleck = 3.2

-------

`$$\psi = -.5(3) + -.5(2.6) + .5(1.2) + .5(3.2) \\
\psi = -0.6$$`

---

## Calculating the F

- Mean square error within is .8 (go back to omnibus test)
- `\(\psi = -0.6\)`
- `\(n\)` per group = 5

`$$F = \frac{\psi^2}{MS_\text{Within}\Sigma(c_j^2/n_j)} \\
F = \frac{-.6^2}{.8\Sigma[(-.5^2/5) + (-.5^2/5) + (.5^2/5) + (.5^2/5)]} \\
F = 2.25$$`

Critical value `\(F(1, 16) = 4.49\)`

Cannot reject `\(H_0\)`. There is not sufficient evidence to say that the average of older Batmen is different from the average of younger Batmen

---
class: inverse

## Next time...

Twoway (factorial) ANOVA

If your work is with neuroimaging, this is required reading for why mutliple comparisons are a problem: 

- Bennett, C. M., Baird, A. A., Miller, M. B., &amp; Wolford, G. L. (2010). Neural Correlates of Interspecies Perspective Taking in the Post-Mortem Atlantic Salmon: An Arugment For Proper Multiple Comparisons Correction. Journal of Serendipitous and Unexpected Results, 1(1), 1â€“5.
- https://teenspecies.github.io/pdfs/NeuralCorrelates.pdf

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
