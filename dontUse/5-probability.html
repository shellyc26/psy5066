<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Fisher Tradition and Probability</title>
    <meta charset="utf-8" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/rladies.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/rladies-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Fisher Tradition and Probability

---


In research, we wish to make inferences about the **unknown** state of the world based on **known** data we have in hand.


We often accomplish this by determining how rare or unusual our data are under alternative models.  On that basis we might reject some models as implausible.  We might even be able to state how confident we are in that conclusion. This is **statistical inference**.


The language of how rare or unusual (or common or typical) the data might be is the language of **probability**.  

---

## What Fisher Suggested

- Set up a statistical null hypothesis (note: null does NOT mean nil)
- Report the exact level of significance
- Do not use a "conventional" level, do not talk about accepting or rejecting hypotheses, do not pas Go, and do not collect $200
- Use this procedure *only* if you know very little about the problem at hand

---

## Neyman-Pearson

- Set up two hypotheses, and design a study based on the "rejection region" for each hypothesis
- If data is within rejection range for H1, accept H2. Otherwise, accept H1. Note that accepting it doesn't mean you believe in it, just that you act as though it was so.
Utility is limited to situations where there is a clear differences in hypotheses, and when you can make a rational decision about when to accept versus reject H1 and H2

---
## What we're stuck with -- A merger

- Unfortunately, these 2 ideas were melded together into something neither camp would be too excited by

1. Set up a null hypothesis, where null almost always means "chance"
2. Make a yes-no decision about that hypothesis
3. Repeat

---
## Basic Premise

What we want to know:

  - What is the probability that we would get the values evidenced *(or those more extreme)* given our null hypothesis?

--

  - `\(p\)`-value = `\(P(Data|H_{0})\)`

--

  - Assumes, among other things, that the null is exactly true, that you have a random sample, and the scores are independent 

---
class: inverse

## Basics of Probability

---

## Events

1. `\(0\)` is less than or equal to `\(P(A)\)` which is less than or equal to `\(1\)`
2. In a sample space with `\(n\)` possible outcomes, each event has a **probability** and the sum of these probabilities is 1.

???
Example, you have a fair coin. the probability of heads is .5 and the proability of tails is .5. this adds up to 1. 

---

## P(Miss Scarlet)



  
  

## Some terminology

An **elementary event** is a member of the mutually exclusive and exhaustive outcomes that can happen when we make an observation.

- For a coin toss, there are two elementary events.

- For rolling a die, there are six elementary events.

- For drawing tiles out of a Scrabble bag, there are 27 elementary events.

--

The **sample space** is the set of all possible elementary events.

???

Define mutually exclusive - they cannot occur at the same time. you're either getting a heads or a tails from a single coin toss. 

Define exhaustive - at least one of the events MUST occur. if you roll a die, you're going to get a 1 or 2 or 3 or 4 or 5 or 6. But you can't get a 1 &amp; and 6 on a single roll. so in a single roll, 1 &amp; six are mutually exclusive. 


---

## Random Variables

Absent additional information, we assume that what happens from outcome to outcome, as we observe events in the sample space, is random. The outcome is determined *only* by chance.  


For that reason, the variable we define to represent the outcome of events in a sample space is called a **random variable**. 

- The term, **stochastic variable**, is also used and means the same thing.


???

Random = outcome is determined by chance alone
---

### More terminology

A **non-elementary event** is composed of two or more elementary events.

- For rolling a die, even numbers are a non-elementary event composed of tosses resulting in 2, 4, or 6.

- For drawing tiles out of a Scrabble bag, vowels are non-elementary events composed of drawing the tiles A, E, I, O, and U.

--

The sample space can be divided into non-elementary events in multiple ways.

- Scrabble tiles can be categorized as vowels and consonants (or both), but also according to their point values.

---

### More terminology

To get the probability of A occuring ($p(A)$), if each event is equally probable, then `$$p(A) = \frac{n(A)}{N}$$`

- `\(p(Rolling a 5) = \frac{1}{6}\)`
- `\(p(Heads) = \frac{1}{2} = .5\)`

--

Each elementary event (and non-elementary event) has a **probability** and the sum of these probabilities is 1.  

- `\(p(Heads) + p(Tails)\)`
- `\(.5 + .5\)`
- `\(1\)`

---

## Probability Distribution

The display of the elementary events and their probabilities is called a **probability distribution**.  

---

## Probability Distribution

The display of the elementary events and their probabilities is called a **probability distribution**.  

- For coin tosses and die rolls, this distribution is discrete and uniform. 


![](5-probability_files/figure-html/unnamed-chunk-2-1.png)&lt;!-- --&gt;

---

## Probability Distribution

The display of the elementary events and their probabilities is called a **probability distribution**.  

- For Scrabble tile draws, this distribution is discrete and non-uniform. 

![](5-probability_files/figure-html/unnamed-chunk-3-1.png)&lt;!-- --&gt;

---
## Probability Distribution

The display of the elementary events and their probabilities is called a **probability distribution**. 

- Other distributions we will encounter are continuous.

???
discrete = countable
uniform = rectangular

---

## Probability Distributions

Probability distributions have **parameters** that define the nature of the distribution.  

- These may be as simple as a single probability (die roll outcomes) or include additional information to describe, for example, variability.

*Once we know the parameters, we know everything we need to construct the sample space and the probability distribution.*  

- We know what to expect in the data as we encounter outcomes in the sample space.

---

## Rules of probabilities
`$$\Large \text{not A} = P(\neg A) = 1-P(A)$$`
--

If your events are independent (the information that 1 event has occured does *not* affect the probability of the other event):

`$$\Large \text{A or B} = P(A \cup B) = P(A) + P(B)$$`
`$$\Large \text{A and B }= P (A \cap B) = P(A)P(B)$$`

--

If your events are NOT independent 

`$$\Large \text{A or B} = P(A \cup B) = P(A) + P(B) - P(A \cap B)$$`

`$$\Large \text{A and B }= P (A \cap B) = P(A|B)P(B)$$`


???

`\(\Large \neg\)` is the complement of A

we need to take into account what has already happened when deciding what value of probability to use for a *subsequent* event. So for the last line, probability of A AND B, if they are not indepdendent, then we can't just multiple. We need to say what is the probability that A has occured GIVENT that B has occured. so we take the probability of A given B, and multiple that by the probability of B to give us the probability or A &amp; B when these are not indepednent.
---

## Frequentist Viewpoint

- Frequentist vs. Bayesian (we'll talk about Bayesian stuff later)
- **Frequentist** view is sometimes called the "in the long run" view. It defines probability as what is expected to happen in the long run, if the event in question (e.g., tossing a coin, rolling a die) is repeated over and over.

  - Ex: We know that a fair coin will come up on heads 50% of the time: `\(P(H) = .5\)`
  - A coin flipped a 2 times might come up heads both times (100%), but a head flipped 1000 times would not likely come up heads 1000 times. *In the long run, the proportion of heads will converge on the expected probability.*

---
## Frequentist Viewpoint

This "long run" view of probability means that in "short run" the outcomes will not behave as expected—the outcomes will show variability around the expected probability outcome. ]

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

The utility here is that we know what the truth is and can see how closely we approximate it in the long run, but also see what happens in realistic short run circumstances:

- Tossing a coin: proportion of heads, P(H) = .5

- Rolling a die: proportion of sixes, P(6) = .1666

- Selecting a Scrabble tile: proportion of Zs, P(Z)=.01

---

## Simulations of probability

Simulation here will confirm what we know must be true given the defined model, but will also give a sense of how far off the mark short-run results can be.This is valuable because we never have an infinite series of events; rarely do we have very long ones. We live in a short-run world and need to know how that affects inferences that we want to make.



---

class: center

## Simulations of probability

![](5-probability_files/figure-html/unnamed-chunk-5-1.png)&lt;!-- --&gt;

???

When small samples of coin tosses are used, the proportion of heads can be off the mark by a fair amount.

Knowing this is important when we flip the process around and ask, "how reasonable is a model that assumes P = .5, given what I have found in my data?"

---
class: center

## Simulations of probability

![](5-probability_files/figure-html/unnamed-chunk-6-1.png)&lt;!-- --&gt;

???

Note that the expected probability is lower for this event.

It converges on the expected value faster. 

---
class: center

## Simulations of probability
![](5-probability_files/figure-html/unnamed-chunk-7-1.png)&lt;!-- --&gt;

???

And even faster here.  All of these events are binary.  The behavior we see in the outcomes (expected value and variability) is related to the expected value.

The binomial distribution will formally define this behavior. 

---

The frequentist view is popular because it is objective.  The events in question are observable and the definition of probability (proportion of an event in the long run) is calculated in the same way by everyone.

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

On the other hand, in real life, "the long run" may not have a simple or realistic meaning: 

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

"The probability that Sara has her phone with her today is .8, or 80%."

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

At one level, we all have an intuitive feel for what this means and understand it to tell us that Sara likely does not have her phone.

---

But, in the strict sense, that statement doesn’t have a sensible meaning in the language of a frequentist view.

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

I either do or I do not have my phone with me today (there are only two outcomes in the sample space); it makes no sense to say that I have 80% of my phone with me today and the event is not repeatable (having my phone today) in the strict sense, so the “long run” doesn’t seem to apply.

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

Instead, we have to say something like, on days like today (which can be repeated), the probability that Sara has her phone with her is .8.  

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

Probability and statistics involve many such convenient fictions.  What are the implications?


???

They allow us to get on with the job of forecasting from models to data or making inferences when going from data to models.

---

The link between probability and statistics is clear when we make the move to inference—the major task in science.

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

In probability, the model (the probability distribution, the generating function) is known and informs us what will be true about the data.  

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

In statistical inference, the model is not known and we let the data inform us about the plausibility of different models that might be true.  

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

We have to make assumptions about those models in order to sensibly answer the inference question.

---

If this coin is fair (proposed model), I expect the proportion of heads to be .5 in the long run.

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

After a long run (data collection), I find the proportion of heads to be .75.  I reject the "fair coin model."  I could be wrong but will try to limit the mistakes.  

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

This is statistical inference.  It relies upon assuming some generating process for the events (a model), typically defined by a theoretical probability distribution (here the binomial).  That framework allows us know the likelihood that we are wrong in our inference, especially in the short run.

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

Probability and probability distributions provide a frame of reference for making inferences.

---

## Example: Which model?

Three competing models are available to explain the occurrence of a target event.

- Model A: `\(p(E) = .70\)`
- Model B: `\(p(E) = .75\)`
- Model C: `\(p(E) = .45\)`

I assume that this target event follows a binomial probability distribution. If that model is correct, at what point can I distinguish the models and declare a winner?

---

class: center





![](5-probability_files/figure-html/test_models-1.png)&lt;!-- --&gt;

Three competing models are available to explain the occurrence of a target event.  

I assume that this target event follows a binomial probability distribution. If that model is correct, at what point can I distinguish the models and declare a winner?

---

class: center




![](5-probability_files/figure-html/unnamed-chunk-10-1.png)&lt;!-- --&gt;


Three competing models are available to explain the occurrence of a target event.  

I assume that this target event follows a binomial probability distribution. If that model is correct, at what point can I distinguish the models and declare a winner?
---

class: center




![](5-probability_files/figure-html/unnamed-chunk-12-1.png)&lt;!-- --&gt;


Three competing models are available to explain the occurrence of a target event.  

I assume that this target event follows a binomial probability distribution. If that model is correct, at what point can I distinguish the models and declare a winner?

---

class: center

## Example: Same model?

My theory claims that the same underlying process (an assumption, here the binomial) governs the outcomes in three populations.  At what point can I make a confident claim about that assertion?


---

class: center





![](5-probability_files/figure-html/which_samp-1.png)&lt;!-- --&gt;

My theory claims that the same underlying process (an assumption, here the binomial) governs the outcomes in three populations.  At what point can I make a confident claim about that assertion?

???

Are the data in these populations generated by the same underlying process (model)?

---

class: center




![](5-probability_files/figure-html/unnamed-chunk-15-1.png)&lt;!-- --&gt;

My theory claims that the same underlying process (an assumption, here the binomial) governs the outcomes in three populations.  At what point can I make a confident claim about that assertion?

???

Are the data in these populations generated by the same underlying process (model)?

---

class: center





![](5-probability_files/figure-html/unnamed-chunk-17-1.png)&lt;!-- --&gt;

My theory claims that the same underlying process (an assumption, here the binomial) governs the outcomes in three populations.  At what point can I make a confident claim about that assertion?

???

Are the data in these populations generated by the same underlying process (model)?

---

### Distributions and their distinctions.

**Population distribution:** the usually hypothetical set of all possible measurements.  

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

- In the frequentist view this would be an infinitely long series of events.  

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

- In practice, we have to settle for “really long.”

&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

**Sample distribution:** the set of measurements in hand, assumed to be a random sample from the population. 

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

- I will use statistics about the sample to infer what is true about population parameters.

---

###Distributions and their distinctions.

**Sampling distribution:** Any sample will be off the mark in the value of a statistic relative to the population.  These statistic values will have a distribution across different random samples of the same size from the same population.  The variability in that distribution will tell us about the precision of the sample as a population estimate and the confidence we can have in claims we make about parameters.

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

- Long run version (repeated sampling interpretation)

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

- Theoretical version

*More on both of these when we talk about sampling.*

---

## Bayesian statistics

In contrast to the frequentist view, the Bayesian view takes prior beliefs into account in determining the probability of an event.  

- It is a model of rational thinking that adjusts current beliefs about the probability of an event given previous knowledge or beliefs.  

- Because those prior beliefs could come from anywhere, the approach is sometimes labeled "subjectivist," but it need not be hopelessly subjective.

The key contribution can be summarized in Bayes’ Theorem:

`$$\Large \text{A given B} = P(A|B) = \frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|\neg A)P(\neg A)}$$`

---

### Bayesian example

I have the personal theory that, generally speaking, Bayesians are smug.  I meet a smug person. What is the probability that I have met a Bayesian?

`$$\large \text{Bayesian | Smug} = P(B|S) = \frac{P(S|B)P(B)}{P(S|B)P(B) + P(S|\neg B)P(\neg B)}$$`
`\(P(B) = .1 \text{(Bayesian are not common, overall)}\)`

`\(P(S|B) = .8\)`

`\(P(S|\neg B) = .3\)`

`$$\large \text{Bayesian | Smug} = P(B|S) = \frac{(.8)(.1)}{(.8)(.1) + (.3)(.9)} = 0.229$$`
---

`\(P(B) = .1\)`

`\(P(S|B) = .8\)`

`\(P(S|\neg B) = .3\)`

`\(P(B|S) = 0.229\)`

From a pure baserate standpoint I should assume the probability is .1 that this person is a Bayesian.  Bayesian reasoning tells me to take my prior beliefs into account given what I believe to be true about the relation of smugness to Bayesian status.

&lt;p&gt;&amp;nbsp;&lt;/p&gt;
--
But, it also tells me not to be too enthusiastic about this Bayesian attribution.  I should not just flip around my conditional probability of "smugness given Bayesian" and claim the probability is .8 that I’ve just encountered a Bayesian. 

--
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
In the language of Bayes Theory, P(B) is called the **prior probability**, P(B|S) is the **posterior probability**, which is an adjustment of P(B) in the face of additional information (smugness).

---

The liberal sprinkling of the term, belief, in all this is what garners the label, subjectivist.

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

There is no need for P(B) or P(S|B) to be point estimates.  We can express uncertainty about these beliefs by making them *probability distributions*. The result is a posterior probability distribution.  I can use actual data to help me decide which of several different models about Bayesian-smugness beliefs is the better account.

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

There is no controversy when the prior information is based on solid scientific evidence.

---

## Another Bayesian example

My doctor calls me with the results of a diagnostic test for a very rare but always fatal medical condition.  I ask about the nature of the test and he tells me it has a sensitivity of .99 and specificity of .99, based on a large number of clinical studies.  How worried should I be? What is the probability that I will actually get this disease?

--

Assume that in the population, 1 out of every 10,000 people gets the condition: P(Disease) = .0001. 

The sensitivity tells me that P(Positive Test|Disease) is .99.

The specificity tells me that P(Positive Test|No Disease) is .01.

What is the probability that I will get this disease given that I have a positive test?  P(Disease|Positive Test) = .0098

???

Before transitioning, need to know probability of rare disease.

`$$\frac{(.99)(.0001)}{(.99)(.0001)+(.01)(.9999)}$$`

---
## `\(p\)`-values

Soon enough, we'll get to how `\(p\)`-values are derived from data. But it's worth bringing them up now, because they are statments about probability. 

What are `\(p\)`-values representing the probability of?

--

Which view of probability, frequentist or Bayesian, are `\(p\)`-values associated with?

---

## Likelihood under different views

.pull-left[
### Frequentist

`$$p = P(\text{Data}|H_0)$$`
]

.pull-right[
### Bayesian
`$$\text{Bayes Factor} = \frac{P(\text{Data}|H_A)}{P(\text{Data}|H_0)}$$`
]

Which is right?

* `\(p\)`-values and Bayes Factor are highly correlated ([Wetzels et al., 2011](../readings/Wetzels_etal_2011.pdf)).



???

Note that `\(H_A\)` can be a range of possible parameters, in which case, you get the weighted probability across many, or the integral if a continuous range. 

---

&lt;img src="images/BF_pvalue.png" width="75%" /&gt;

.small[([Wetzels et al., 2011](../readings/Wetzels_etal_2011.pdf))]

???
But major disagreement in conclusion.

- When `\(p\)`-value falls between .01 and .05, there is a 70% chance that Bayes Factor suggests only anecdotal evidence in favor of alternative. 

Take-away -- Bayes Factor is more conservative when it comes to finding evidence against the null hypothesis. Is that better, or worse?

---

class: inverse

## Next time...

binomial distribution
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
